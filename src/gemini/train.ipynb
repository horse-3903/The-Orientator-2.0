{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import random\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/cloud-platform\", \"https://www.googleapis.com/auth/generative-language.tuning\"]\n",
    "KEY_FILE = os.getenv(\"PARENT_DIR\") + \"auth/credentials.json\"\n",
    "TOKEN_FILE = os.getenv(\"PARENT_DIR\") + \"auth/token.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = None\n",
    "\n",
    "if os.path.exists(TOKEN_FILE):\n",
    "    creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)\n",
    "\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(KEY_FILE, SCOPES)\n",
    "        creds = flow.run_local_server()\n",
    "    \n",
    "    with open(TOKEN_FILE, \"w\") as token:\n",
    "        token.write(creds.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='models/gemini-1.5-pro',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       "    cached_content=None\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(name='models/gemini-1.0-pro-001',\n",
       "      base_model_id='',\n",
       "      version='001',\n",
       "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
       "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
       "                   'model that supports tuning.'),\n",
       "      input_token_limit=30720,\n",
       "      output_token_limit=2048,\n",
       "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
       "      temperature=0.9,\n",
       "      max_temperature=None,\n",
       "      top_p=1.0,\n",
       "      top_k=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = [m for m in genai.list_models() if \"createTunedModel\" in m.supported_generation_methods][0]\n",
    "base_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text_input': 'What is your name?', 'output': 'My name is The Orientator'},\n",
       " {'text_input': 'What do you do?',\n",
       "  'output': 'I am an AI Chatbot named The Orientator, and my purpose is to help you understand HCI better.'},\n",
       " {'text_input': 'How can you help me?',\n",
       "  'output': 'You can ask me questions about the HCI, and I will try my best to help you answer them.'},\n",
       " {'text_input': 'Who are you?',\n",
       "  'output': 'I am an AI Chatbot named The Orientator, and my purpose is to help you understand HCI better.'},\n",
       " {'text_input': 'What are you?',\n",
       "  'output': 'I am an AI Chatbot named The Orientator, and my purpose is to help you understand HCI better.'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.getenv(\"PARENT_DIR\") + \"data/final_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "    training_data = [{\"text_input\": a, \"output\": b} for a, b in data]\n",
    "\n",
    "training_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"test-model-3\"\n",
    "operation = genai.create_tuned_model(\n",
    "    source_model=base_model.name,\n",
    "    training_data=training_data,\n",
    "    id = name,\n",
    "    epoch_count = 100,\n",
    "    batch_size = 4,\n",
    "    learning_rate = 0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18900 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18900 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18900 [00:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18900 [00:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/18900 [00:21<17:34:30,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 1\n",
      "completed_percent: 0.00529100513\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/18900 [00:24<17:07:13,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 2\n",
      "completed_percent: 0.0105820103\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 2\n",
      "  mean_loss: 52.9196777\n",
      "  compute_time {\n",
      "    seconds: 1723308552\n",
      "    nanos: 948856970\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/18900 [00:27<16:56:04,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 3\n",
      "completed_percent: 0.0158730168\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 2\n",
      "  mean_loss: 52.9196777\n",
      "  compute_time {\n",
      "    seconds: 1723308552\n",
      "    nanos: 948856970\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 3\n",
      "  mean_loss: 94.9239044\n",
      "  compute_time {\n",
      "    seconds: 1723308556\n",
      "    nanos: 5011232\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/18900 [00:32<19:47:42,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 4\n",
      "completed_percent: 0.0211640205\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 2\n",
      "  mean_loss: 52.9196777\n",
      "  compute_time {\n",
      "    seconds: 1723308552\n",
      "    nanos: 948856970\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 3\n",
      "  mean_loss: 94.9239044\n",
      "  compute_time {\n",
      "    seconds: 1723308556\n",
      "    nanos: 5011232\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 4\n",
      "  mean_loss: 38.3271255\n",
      "  compute_time {\n",
      "    seconds: 1723308560\n",
      "    nanos: 152347824\n",
      "  }\n",
      "}\n",
      "\n",
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 4\n",
      "completed_percent: 0.0211640205\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 2\n",
      "  mean_loss: 52.9196777\n",
      "  compute_time {\n",
      "    seconds: 1723308552\n",
      "    nanos: 948856970\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 3\n",
      "  mean_loss: 94.9239044\n",
      "  compute_time {\n",
      "    seconds: 1723308556\n",
      "    nanos: 5011232\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 4\n",
      "  mean_loss: 38.3271255\n",
      "  compute_time {\n",
      "    seconds: 1723308560\n",
      "    nanos: 152347824\n",
      "  }\n",
      "}\n",
      "\n",
      "tuned_model: \"tunedModels/test-model-3\"\n",
      "total_steps: 18900\n",
      "completed_steps: 4\n",
      "completed_percent: 0.0211640205\n",
      "snapshots {\n",
      "  step: 1\n",
      "  mean_loss: 106.330048\n",
      "  compute_time {\n",
      "    seconds: 1723308537\n",
      "    nanos: 224984800\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 2\n",
      "  mean_loss: 52.9196777\n",
      "  compute_time {\n",
      "    seconds: 1723308552\n",
      "    nanos: 948856970\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 3\n",
      "  mean_loss: 94.9239044\n",
      "  compute_time {\n",
      "    seconds: 1723308556\n",
      "    nanos: 5011232\n",
      "  }\n",
      "}\n",
      "snapshots {\n",
      "  step: 4\n",
      "  mean_loss: 38.3271255\n",
      "  compute_time {\n",
      "    seconds: 1723308560\n",
      "    nanos: 152347824\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\generativeai\\operations.py:126\u001b[0m, in \u001b[0;36mCreateTunedModelOperation.wait_bar\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m bar \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mtotal_steps, initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# done() includes a `_refresh_and_update`\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    127\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\n\u001b[0;32m    128\u001b[0m     bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mcompleted_steps \u001b[38;5;241m-\u001b[39m bar\u001b[38;5;241m.\u001b[39mn)\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\operation.py:174\u001b[0m, in \u001b[0;36mOperation.done\u001b[1;34m(self, retry)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdone\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks to see if the operation is complete.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03m        bool: True if the operation is complete, False otherwise.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh_and_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mdone\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\operation.py:162\u001b[0m, in \u001b[0;36mOperation._refresh_and_update\u001b[1;34m(self, retry)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# If the currently cached operation is done, no need to make another\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# RPC as it will not change once done.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh(retry\u001b[38;5;241m=\u001b[39mretry) \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_refresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_result_from_operation()\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\operations_v1\\operations_client.py:159\u001b[0m, in \u001b[0;36mOperationsClient.get_operation\u001b[1;34m(self, name, retry, timeout, compression, metadata)\u001b[0m\n\u001b[0;32m    156\u001b[0m metadata \u001b[38;5;241m=\u001b[39m metadata \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    157\u001b[0m metadata\u001b[38;5;241m.\u001b[39mappend(gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name}))\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\grpc\\_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1168\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1175\u001b[0m     (\n\u001b[0;32m   1176\u001b[0m         state,\n\u001b[0;32m   1177\u001b[0m         call,\n\u001b[1;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\chong\\Desktop\\Coding\\GitHub\\The-Orientator-2.0\\venv\\Lib\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:400\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for status in operation.wait_bar():\n",
    "    time.sleep(2)\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TunedModel(name='tunedModels/test-model-2',\n",
       "           source_model='models/gemini-1.0-pro-001',\n",
       "           base_model='models/gemini-1.0-pro-001',\n",
       "           display_name='',\n",
       "           description='',\n",
       "           temperature=0.9,\n",
       "           top_p=1.0,\n",
       "           top_k=0,\n",
       "           state=<State.ACTIVE: 2>,\n",
       "           create_time=datetime.datetime(2024, 8, 8, 5, 41, 18, 728520, tzinfo=datetime.timezone.utc),\n",
       "           update_time=datetime.datetime(2024, 8, 8, 9, 5, 2, 466322, tzinfo=datetime.timezone.utc),\n",
       "           tuning_task=TuningTask(start_time=datetime.datetime(2024, 8, 8, 5, 41, 21, 780055, tzinfo=datetime.timezone.utc),\n",
       "                                  complete_time=datetime.datetime(2024, 8, 8, 9, 5, 2, 466322, tzinfo=datetime.timezone.utc),\n",
       "                                  snapshots=[...],\n",
       "                                  hyperparameters=Hyperparameters(epoch_count=100,\n",
       "                                                                  batch_size=4,\n",
       "                                                                  learning_rate=0.001)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.get_tuned_model(f\"tunedModels/{name}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genai.GenerativeModel(\n",
       "    model_name='tunedModels/test-model-2',\n",
       "    generation_config={},\n",
       "    safety_settings={},\n",
       "    tools=None,\n",
       "    system_instruction=None,\n",
       "    cached_content=None\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=f\"tunedModels/{name}\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Fun things to do in HCI (non-exhaustive)**\n",
      "\n",
      "* **Basketball** (Note: Do note that the courts are very popular and you may not be able to play on it)\n",
      "* **Table tennis** (Note: Do note that the tables are very popular and you may not be able to play on it)\n",
      "* **Going to the track to run/jog** (Note: Do note that track and field CCA teams use the track and you may not be able to use it)\n",
      "* **Going to the gym (Note: Do note that you need to pay to use it)\n",
      "* **Chilling at the track/EP3 (Note: Do note that track and field CCA teams use the track and you may not be able to use it)\n",
      "* **Going to the library to study/find a book to read (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the darkroom to develop photos (Note: Do note that you need to pay to use it)\n",
      "* **Playing the piano at the Clocktower/LT400 (Note: Do note that you need to check if there are any events on that day before playing the piano)\n",
      "* **Taking photos at the track/EP3/HC (Note: Do note that you may not be able to take photos of people without their consent)\n",
      "* **Going to the second floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the fourth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the fifth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the sixth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the seventh floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the eighth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the ninth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the tenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the eleventh floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the twelfth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the thirteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the fourteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the fifteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the sixteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the seventeenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the eighteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the nineteenth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n",
      "* **Going to the twentieth floor of the track to study/find a place to eat lunch (Note: Do note that you need to keep quiet as people are studying there)\n"
     ]
    }
   ],
   "source": [
    "content = model.generate_content(\"What can I do leisurely in HCI?\")\n",
    "print(content.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
